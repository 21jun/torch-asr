{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_url=\"train-clean-100\"\n",
    "test_url=\"test-clean\"\n",
    "train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[-0.0059, -0.0045, -0.0067,  ...,  0.0007,  0.0034,  0.0047]]),\n",
       " 16000,\n",
       " \"THAT HAD ITS SOURCE AWAY BACK IN THE WOODS OF THE OLD CUTHBERT PLACE IT WAS REPUTED TO BE AN INTRICATE HEADLONG BROOK IN ITS EARLIER COURSE THROUGH THOSE WOODS WITH DARK SECRETS OF POOL AND CASCADE BUT BY THE TIME IT REACHED LYNDE'S HOLLOW IT WAS A QUIET WELL CONDUCTED LITTLE STREAM\",\n",
       " 103,\n",
       " 1240,\n",
       " 1)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_wer(wer_scores, combined_ref_len):\n",
    "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
    "\n",
    "\n",
    "def _levenshtein_distance(ref, hyp):\n",
    "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
    "    between two sequences. Informally, the levenshtein disctance is defined as\n",
    "    the minimum number of single-character edits (substitutions, insertions or\n",
    "    deletions) required to change one word into the other. We can naturally\n",
    "    extend the edits to word level when calculate levenshtein disctance for\n",
    "    two sentences.\n",
    "    \"\"\"\n",
    "    m = len(ref)\n",
    "    n = len(hyp)\n",
    "\n",
    "    # special case\n",
    "    if ref == hyp:\n",
    "        return 0\n",
    "    if m == 0:\n",
    "        return n\n",
    "    if n == 0:\n",
    "        return m\n",
    "\n",
    "    if m < n:\n",
    "        ref, hyp = hyp, ref\n",
    "        m, n = n, m\n",
    "\n",
    "    # use O(min(m, n)) space\n",
    "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
    "\n",
    "    # initialize distance matrix\n",
    "    for j in range(0,n + 1):\n",
    "        distance[0][j] = j\n",
    "\n",
    "    # calculate levenshtein distance\n",
    "    for i in range(1, m + 1):\n",
    "        prev_row_idx = (i - 1) % 2\n",
    "        cur_row_idx = i % 2\n",
    "        distance[cur_row_idx][0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            if ref[i - 1] == hyp[j - 1]:\n",
    "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
    "            else:\n",
    "                s_num = distance[prev_row_idx][j - 1] + 1\n",
    "                i_num = distance[cur_row_idx][j - 1] + 1\n",
    "                d_num = distance[prev_row_idx][j] + 1\n",
    "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
    "\n",
    "    return distance[m % 2][n]\n",
    "\n",
    "\n",
    "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in word-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Levenshtein distance and word number of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    ref_words = reference.split(delimiter)\n",
    "    hyp_words = hypothesis.split(delimiter)\n",
    "\n",
    "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
    "    return float(edit_distance), len(ref_words)\n",
    "\n",
    "\n",
    "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
    "    hypothesis sequence in char-level.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Levenshtein distance and length of reference sentence.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    if ignore_case == True:\n",
    "        reference = reference.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "    join_char = ' '\n",
    "    if remove_space == True:\n",
    "        join_char = ''\n",
    "\n",
    "    reference = join_char.join(filter(None, reference.split(' ')))\n",
    "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
    "\n",
    "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
    "    return float(edit_distance), len(reference)\n",
    "\n",
    "\n",
    "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
    "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
    "    hypothesis text in word-level. WER is defined as:\n",
    "    .. math::\n",
    "        WER = (Sw + Dw + Iw) / Nw\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sw is the number of words subsituted,\n",
    "        Dw is the number of words deleted,\n",
    "        Iw is the number of words inserted,\n",
    "        Nw is the number of words in the reference\n",
    "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
    "    that empty items will be removed when splitting sentences by delimiter.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param delimiter: Delimiter of input sentences.\n",
    "    :type delimiter: char\n",
    "    :return: Word error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If word number of reference is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
    "                                         delimiter)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
    "\n",
    "    wer = float(edit_distance) / ref_len\n",
    "    return wer\n",
    "\n",
    "\n",
    "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
    "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
    "    hypothesis text in char-level. CER is defined as:\n",
    "    .. math::\n",
    "        CER = (Sc + Dc + Ic) / Nc\n",
    "    where\n",
    "    .. code-block:: text\n",
    "        Sc is the number of characters substituted,\n",
    "        Dc is the number of characters deleted,\n",
    "        Ic is the number of characters inserted\n",
    "        Nc is the number of characters in the reference\n",
    "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
    "    encoded to unicode. Please draw an attention that the leading and tailing\n",
    "    space characters will be truncated and multiple consecutive space\n",
    "    characters in a sentence will be replaced by one space character.\n",
    "    :param reference: The reference sentence.\n",
    "    :type reference: basestring\n",
    "    :param hypothesis: The hypothesis sentence.\n",
    "    :type hypothesis: basestring\n",
    "    :param ignore_case: Whether case-sensitive or not.\n",
    "    :type ignore_case: bool\n",
    "    :param remove_space: Whether remove internal space characters\n",
    "    :type remove_space: bool\n",
    "    :return: Character error rate.\n",
    "    :rtype: float\n",
    "    :raises ValueError: If the reference length is zero.\n",
    "    \"\"\"\n",
    "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
    "                                         remove_space)\n",
    "\n",
    "    if ref_len == 0:\n",
    "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
    "\n",
    "    cer = float(edit_distance) / ref_len\n",
    "    return cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextTransform:\n",
    "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
    "    def __init__(self):\n",
    "        char_map_str = \"\"\"\n",
    "        ' 0\n",
    "        <SPACE> 1\n",
    "        a 2\n",
    "        b 3\n",
    "        c 4\n",
    "        d 5\n",
    "        e 6\n",
    "        f 7\n",
    "        g 8\n",
    "        h 9\n",
    "        i 10\n",
    "        j 11\n",
    "        k 12\n",
    "        l 13\n",
    "        m 14\n",
    "        n 15\n",
    "        o 16\n",
    "        p 17\n",
    "        q 18\n",
    "        r 19\n",
    "        s 20\n",
    "        t 21\n",
    "        u 22\n",
    "        v 23\n",
    "        w 24\n",
    "        x 25\n",
    "        y 26\n",
    "        z 27\n",
    "        \"\"\"\n",
    "        self.char_map = {}\n",
    "        self.index_map = {}\n",
    "        for line in char_map_str.strip().split('\\n'):\n",
    "            ch, index = line.split()\n",
    "            self.char_map[ch] = int(index)\n",
    "            self.index_map[int(index)] = ch\n",
    "        self.index_map[1] = ' '\n",
    "\n",
    "    def text_to_int(self, text):\n",
    "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
    "        int_sequence = []\n",
    "        for c in text:\n",
    "            if c == ' ':\n",
    "                ch = self.char_map['<SPACE>']\n",
    "            else:\n",
    "                ch = self.char_map[c]\n",
    "            int_sequence.append(ch)\n",
    "        return int_sequence\n",
    "\n",
    "    def int_to_text(self, labels):\n",
    "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
    "        string = []\n",
    "        for i in labels:\n",
    "            string.append(self.index_map[i])\n",
    "        return ''.join(string).replace('<SPACE>', ' ')\n",
    "    \n",
    "\n",
    "    \n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "\targ_maxes = torch.argmax(output, dim=2)\n",
    "\tdecodes = []\n",
    "\ttargets = []\n",
    "\tfor i, args in enumerate(arg_maxes):\n",
    "\t\tdecode = []\n",
    "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
    "\t\tfor j, index in enumerate(args):\n",
    "\t\t\tif index != blank_label:\n",
    "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tdecode.append(index.item())\n",
    "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
    "\treturn decodes, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
    ")\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "text_transform = TextTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "    for (waveform, _, utterance, _, _, _) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == 'valid':\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "        spectrograms.append(spec)\n",
    "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=bs,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16, 1, 128, 1336])\ntorch.Size([16, 293])\n[490, 668, 91, 527, 424, 588, 508, 611, 519, 500, 75, 191, 629, 556, 604, 105]\n[127, 227, 25, 242, 201, 251, 205, 214, 243, 184, 25, 59, 253, 248, 293, 43]\n"
     ]
    }
   ],
   "source": [
    "for a in train_loader:\n",
    "    print(a[0].size())\n",
    "    print(a[1].size())\n",
    "    print(a[2])\n",
    "    print(a[3])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "        \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\":2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 16,\n",
    "        \"epochs\": 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechRecognitionModel(\n",
    "            hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "            hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([16, 1, 128, 1326])\ntorch.Size([16, 663, 29])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, _data in enumerate(train_loader):\n",
    "    spectrograms, labels, input_lengths, label_lengths = _data \n",
    "    spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "\n",
    "    output = model(spectrograms)  # (batch, time, n_class)\n",
    "    print(spectrograms.size())\n",
    "    print(output.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        print(output.size())\n",
    "        print(labels.size())\n",
    "\n",
    "        print(input_lengths)\n",
    "        print(label_lengths)\n",
    "\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "        if batch_idx % 10 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch, iter_meter, ):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
    "\n",
    "\n",
    "def main(learning_rate=5e-4, batch_size=20, epochs=10,\n",
    "        train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
    "\n",
    "    hparams = {\n",
    "        \"n_cnn_layers\": 3,\n",
    "        \"n_rnn_layers\": 5,\n",
    "        \"rnn_dim\": 512,\n",
    "        \"n_class\": 29,\n",
    "        \"n_feats\": 128,\n",
    "        \"stride\":2,\n",
    "        \"dropout\": 0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if not os.path.isdir(\"./data\"):\n",
    "        os.makedirs(\"./data\")\n",
    "\n",
    "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
    "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
    "    \n",
    "    train_dataset = [train_dataset[x] for x in range(1000)]\n",
    "    # test_dataset = test_dataset[:400]\n",
    "    \n",
    "    kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "\n",
    "    model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "        ).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    iter_meter = IterMeter()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
    "        test(model, device, test_loader, criterion, epoch, iter_meter)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SpeechRecognitionModel(\n  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n  (rescnn_layers): Sequential(\n    (0): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (1): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (2): ResidualCNN(\n      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (dropout1): Dropout(p=0.1, inplace=False)\n      (dropout2): Dropout(p=0.1, inplace=False)\n      (layer_norm1): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): CNNLayerNorm(\n        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n  (birnn_layers): Sequential(\n    (0): BidirectionalGRU(\n      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (1): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (2): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (3): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (4): BidirectionalGRU(\n      (BiGRU): GRU(1024, 512, bidirectional=True)\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): GELU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=512, out_features=29, bias=True)\n  )\n)\nNum Model Parameters 23705373\ntorch.Size([614, 10, 29])\ntorch.Size([10, 235])\n[438, 561, 586, 95, 283, 556, 613, 566, 443, 510]\n[145, 160, 234, 29, 140, 235, 227, 225, 173, 179]\n\nevaluating...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-460ff9e52e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlibri_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test-clean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibri_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibri_test_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-99ef66ab0e43>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(learning_rate, batch_size, epochs, train_url, test_url)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_meter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-99ef66ab0e43>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, criterion, epoch, iter_meter)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (time, batch, n_class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, log_probs, targets, input_lengths, target_lengths)\u001b[0m\n\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         return F.ctc_loss(log_probs, targets, input_lengths, target_lengths, self.blank, self.reduction,\n\u001b[0m\u001b[1;32m   1502\u001b[0m                           self.zero_infinity)\n\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mctc_loss\u001b[0;34m(log_probs, targets, input_lengths, target_lengths, blank, reduction, zero_infinity)\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m     \"\"\"\n\u001b[0;32m-> 2200\u001b[0;31m     return torch.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank, _Reduction.get_enum(reduction),\n\u001b[0m\u001b[1;32m   2201\u001b[0m                           zero_infinity)\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 10\n",
    "epochs = 1\n",
    "libri_train_set = \"train-clean-100\"\n",
    "libri_test_set = \"test-clean\"\n",
    "\n",
    "model = main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/test.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 128, 1332])\n",
      "torch.Size([16, 666, 29])\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "for batch_idx, _data in enumerate(train_loader):\n",
    "    spectrograms, labels, input_lengths, label_lengths = _data \n",
    "    spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "    # optimizer.zero_grad()\n",
    "\n",
    "    output = model(spectrograms)  # (batch, time, n_class)\n",
    "    print(spectrograms.size())\n",
    "    print(output.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.6647, -2.5022, -3.6351,  ..., -5.0386, -8.0121, -0.5571],\n",
      "         [-6.8531, -2.4955, -3.6566,  ..., -5.1169, -8.4000, -0.5262],\n",
      "         [-6.8810, -2.5072, -3.6538,  ..., -5.1093, -8.4962, -0.5236],\n",
      "         ...,\n",
      "         [-6.8074, -2.5121, -3.6683,  ..., -5.0990, -8.4635, -0.5223],\n",
      "         [-6.7569, -2.5213, -3.6790,  ..., -5.1187, -8.3895, -0.5142],\n",
      "         [-6.5452, -2.5574, -3.6597,  ..., -5.0705, -8.0704, -0.5218]],\n",
      "\n",
      "        [[-6.6654, -2.5017, -3.6347,  ..., -5.0385, -8.0129, -0.5572],\n",
      "         [-6.8537, -2.4950, -3.6562,  ..., -5.1165, -8.4004, -0.5263],\n",
      "         [-6.8815, -2.5066, -3.6535,  ..., -5.1089, -8.4965, -0.5237],\n",
      "         ...,\n",
      "         [-6.8083, -2.5113, -3.6684,  ..., -5.0993, -8.4645, -0.5224],\n",
      "         [-6.7581, -2.5204, -3.6793,  ..., -5.1192, -8.3910, -0.5141],\n",
      "         [-6.5468, -2.5565, -3.6601,  ..., -5.0713, -8.0725, -0.5216]],\n",
      "\n",
      "        [[-6.6658, -2.5012, -3.6344,  ..., -5.0384, -8.0132, -0.5573],\n",
      "         [-6.8540, -2.4946, -3.6560,  ..., -5.1163, -8.4006, -0.5263],\n",
      "         [-6.8817, -2.5062, -3.6534,  ..., -5.1086, -8.4968, -0.5238],\n",
      "         ...,\n",
      "         [-6.8082, -2.5111, -3.6683,  ..., -5.0991, -8.4647, -0.5224],\n",
      "         [-6.7581, -2.5202, -3.6792,  ..., -5.1190, -8.3912, -0.5141],\n",
      "         [-6.5469, -2.5563, -3.6601,  ..., -5.0713, -8.0728, -0.5215]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6666, -2.5005, -3.6332,  ..., -5.0386, -8.0142, -0.5574],\n",
      "         [-6.8549, -2.4939, -3.6550,  ..., -5.1161, -8.4021, -0.5264],\n",
      "         [-6.8824, -2.5055, -3.6525,  ..., -5.1081, -8.4985, -0.5238],\n",
      "         ...,\n",
      "         [-6.8084, -2.5106, -3.6685,  ..., -5.0990, -8.4661, -0.5224],\n",
      "         [-6.7584, -2.5197, -3.6795,  ..., -5.1194, -8.3927, -0.5141],\n",
      "         [-6.5470, -2.5559, -3.6605,  ..., -5.0719, -8.0741, -0.5215]],\n",
      "\n",
      "        [[-6.6666, -2.5006, -3.6330,  ..., -5.0383, -8.0143, -0.5575],\n",
      "         [-6.8549, -2.4940, -3.6549,  ..., -5.1158, -8.4025, -0.5264],\n",
      "         [-6.8825, -2.5056, -3.6524,  ..., -5.1078, -8.4989, -0.5238],\n",
      "         ...,\n",
      "         [-6.8083, -2.5105, -3.6685,  ..., -5.0989, -8.4665, -0.5224],\n",
      "         [-6.7583, -2.5196, -3.6796,  ..., -5.1193, -8.3929, -0.5141],\n",
      "         [-6.5467, -2.5557, -3.6605,  ..., -5.0717, -8.0741, -0.5215]],\n",
      "\n",
      "        [[-6.6668, -2.5005, -3.6325,  ..., -5.0379, -8.0143, -0.5576],\n",
      "         [-6.8556, -2.4938, -3.6547,  ..., -5.1157, -8.4030, -0.5264],\n",
      "         [-6.8833, -2.5054, -3.6524,  ..., -5.1078, -8.4999, -0.5238],\n",
      "         ...,\n",
      "         [-6.8090, -2.5101, -3.6689,  ..., -5.0990, -8.4678, -0.5223],\n",
      "         [-6.7589, -2.5191, -3.6800,  ..., -5.1192, -8.3940, -0.5141],\n",
      "         [-6.5469, -2.5552, -3.6606,  ..., -5.0714, -8.0748, -0.5216]]],\n",
      "       device='cuda:0')\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['i little knew him i hardly need to tell you of the awful day that he came home you are already acquainted with the history of it that afternoon shortly after he arrived', 'while measure is the grouping of these beats according to some specified system in listening to a piece of music two hearers a and b may feel the rhythm equally strongly', 'i am sure rosalind will be safe with you', 'and reporters not to encourage us in our peculiar conduct by printing defies to the president of the united states even when flaunted on a pretty little purple and gold banner and exhorts the public to control its thrills', 'there were bunks for ten men in two stages six on one wall and four on the other the furniture of the room consisted of a table a stool for each man and a lux lamp', 'and then again come moments of sudden and universal clarity when several such spirits of the inner world completely fuse together into a wonderful wedlock and many a forgotten bit of our ego shines forth in a new light', 'but each one showed the same strange fear then ameer ali stepped forward this is my duty your majesty he said i will go the king nodded and off he went the night was as dark as pitch', 'a free sunday it did not appear that the great world needed her inspiration but she felt that her letters her contact with the anxieties of men and women all over the country were a part of vast affairs', 'i should have called you to morrow for further test nearly five years of damned hard work to a successful conclusion taylor', 'at the expiration of twenty years had returned from the great wars with a scarred cheek a smiling countenance tranquil admirable pure as a child having done everything for france and nothing against her', 'she is a granddaughter of brigham young slender and graceful with lily white cheeks tinted with clear rose she was brought up in the old salt lake zion house but by some strange chance', 'his was the rental of half havana and all matanzas and santa anna rich as he was could hardly hold a candle to light the mines of gold our cuban owned choke full of diggers and broad plantations that in round figures were stocked with at least five thousand niggers', \"it was a crumpled piece of paper evidently forgotten there by the fugitives in their hurry to get away the sergeant much awed by the citoyen's obvious rage and impatience picked the paper up and handed it respectfully to chauvelin read it sergeant said the latter curtly\", 'scarcely opened her lips dismissed them to the ecstasies of another tete a tete and before it was suffered to close she was enabled to judge how far he was sanctioned by parental authority in his present application', 'are you sure mister woods was in here well no sir not exactly i remember mister farnsworth and mister brown there were probably some others the reason i think mister woods was here', 'it had been an especially hard day in school when she had been absent at the noon hour all the desks in the schoolroom had been piled in a pyramid on the floor books and slates interchanged and various other pranks played']\n",
      "tensor([[[-6.6645, -2.5020, -3.6353,  ..., -5.0382, -8.0117, -0.5572],\n",
      "         [-6.8530, -2.4953, -3.6568,  ..., -5.1167, -8.3993, -0.5262],\n",
      "         [-6.8810, -2.5069, -3.6540,  ..., -5.1093, -8.4958, -0.5237],\n",
      "         ...,\n",
      "         [-6.8077, -2.5120, -3.6687,  ..., -5.0991, -8.4637, -0.5223],\n",
      "         [-6.7574, -2.5212, -3.6795,  ..., -5.1190, -8.3898, -0.5142],\n",
      "         [-6.5457, -2.5573, -3.6604,  ..., -5.0709, -8.0708, -0.5217]],\n",
      "\n",
      "        [[-6.6652, -2.5014, -3.6349,  ..., -5.0384, -8.0123, -0.5573],\n",
      "         [-6.8536, -2.4947, -3.6566,  ..., -5.1165, -8.3997, -0.5263],\n",
      "         [-6.8814, -2.5063, -3.6538,  ..., -5.1090, -8.4961, -0.5238],\n",
      "         ...,\n",
      "         [-6.8082, -2.5113, -3.6688,  ..., -5.0991, -8.4643, -0.5224],\n",
      "         [-6.7582, -2.5204, -3.6798,  ..., -5.1193, -8.3909, -0.5141],\n",
      "         [-6.5470, -2.5565, -3.6607,  ..., -5.0716, -8.0725, -0.5215]],\n",
      "\n",
      "        [[-6.6656, -2.5012, -3.6347,  ..., -5.0385, -8.0126, -0.5573],\n",
      "         [-6.8539, -2.4945, -3.6563,  ..., -5.1164, -8.4000, -0.5264],\n",
      "         [-6.8817, -2.5061, -3.6537,  ..., -5.1088, -8.4963, -0.5238],\n",
      "         ...,\n",
      "         [-6.8083, -2.5110, -3.6687,  ..., -5.0990, -8.4646, -0.5224],\n",
      "         [-6.7584, -2.5201, -3.6797,  ..., -5.1193, -8.3914, -0.5141],\n",
      "         [-6.5474, -2.5563, -3.6607,  ..., -5.0716, -8.0731, -0.5214]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6665, -2.5006, -3.6333,  ..., -5.0385, -8.0141, -0.5574],\n",
      "         [-6.8548, -2.4939, -3.6550,  ..., -5.1161, -8.4020, -0.5264],\n",
      "         [-6.8823, -2.5056, -3.6525,  ..., -5.1081, -8.4984, -0.5238],\n",
      "         ...,\n",
      "         [-6.8084, -2.5106, -3.6685,  ..., -5.0991, -8.4661, -0.5224],\n",
      "         [-6.7583, -2.5198, -3.6795,  ..., -5.1194, -8.3926, -0.5141],\n",
      "         [-6.5470, -2.5559, -3.6605,  ..., -5.0719, -8.0741, -0.5215]],\n",
      "\n",
      "        [[-6.6665, -2.5006, -3.6330,  ..., -5.0383, -8.0143, -0.5575],\n",
      "         [-6.8549, -2.4940, -3.6549,  ..., -5.1158, -8.4024, -0.5264],\n",
      "         [-6.8824, -2.5057, -3.6525,  ..., -5.1078, -8.4988, -0.5238],\n",
      "         ...,\n",
      "         [-6.8083, -2.5105, -3.6685,  ..., -5.0989, -8.4665, -0.5224],\n",
      "         [-6.7583, -2.5196, -3.6796,  ..., -5.1193, -8.3929, -0.5141],\n",
      "         [-6.5467, -2.5557, -3.6605,  ..., -5.0718, -8.0741, -0.5215]],\n",
      "\n",
      "        [[-6.6668, -2.5005, -3.6325,  ..., -5.0379, -8.0143, -0.5576],\n",
      "         [-6.8555, -2.4938, -3.6547,  ..., -5.1157, -8.4030, -0.5264],\n",
      "         [-6.8832, -2.5054, -3.6524,  ..., -5.1078, -8.4998, -0.5238],\n",
      "         ...,\n",
      "         [-6.8090, -2.5101, -3.6689,  ..., -5.0990, -8.4678, -0.5223],\n",
      "         [-6.7589, -2.5191, -3.6800,  ..., -5.1192, -8.3940, -0.5141],\n",
      "         [-6.5469, -2.5552, -3.6606,  ..., -5.0714, -8.0748, -0.5216]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[\"and i supposed him to be still there he always needed a great deal of sleep he sometimes slept until quite late in the morning i had breakfast in my sitting room it was about ten when i heard that my husband's body had been found\", 'at each individual awoke him one of the subjects when questioned afterward as to what sensation he experienced at the snapping of the fingers replied that it seemed to him as if something inside of his head responded', 'my imagination is horribly vivid about her i see her i hear her o that i could be buried near where she lives i am afraid to write to her', \"and depth of another's soul in one hour than it might take you a lifetime to discover if he or she were not disposed to reveal it or if you had not the sense to understand it then you are going to see her this evening\", \"in eske or liddel fords were none but he would ride them one by one alike to him was time or tide december's snow or july's pride alike to him was tide or time moonless midnight or matin prime\", \"but i reckon i have a heart big enough for you all it's a whopper you may depend and every mite and morsel of it at your service well how you do act mister banks half a thousand little clipper clapper tongues would say\", 'the figure in white could be seen hurrying back up the mountain trail evidently the electrical storm with lightning bolts discharging so close was too much for the ghost', 'immediately on your return to your palace go into the bath and cause yourself to be well washed and rubbed then retire to bed and when you rise to morrow you will find yourself cured', \"but the old bulldog of a butler won't let him put his nose inside the door says his name is carteret and he's come all the way from england to see him england not roddy carteret\", 'and though catherine had hoped to explore it accompanied only by his daughter it was a proposal of too much happiness in itself under any circumstances not to be gladly accepted', 'and he knew the young man on whom the fullerton estate must devolve the general needed no more enraged with almost everybody in the world but himself he set out the next day for the abbey where his performances have been seen', 'the storm became inconceivably violent the thermometer fell twenty two degrees in a few minutes and soon dropped below zero the hail gave place to snow and darkness came on like night the wind rising to the highest pitch of violence', 'where an elderly gentleman in uniform sat writing at a table aunt lucy stopped beside him and still holding each by the hand bowed low saying general smith', 'there is citoyen i know it well the englishman is hoping to reach that creek', 'her fair hair was plaited but not adorned she looked patient yet sad', \"and then reported to his master that the old boys were all right at eight o'clock on the evening of the third day the lights of another steamer were seen in the distance and apparently coming up very fast this was a signal for a general commotion on the patriot\"]\n",
      "tensor([[[-6.6646, -2.5023, -3.6352,  ..., -5.0385, -8.0118, -0.5572],\n",
      "         [-6.8526, -2.4956, -3.6567,  ..., -5.1165, -8.3992, -0.5263],\n",
      "         [-6.8808, -2.5072, -3.6540,  ..., -5.1091, -8.4957, -0.5237],\n",
      "         ...,\n",
      "         [-6.8071, -2.5123, -3.6683,  ..., -5.0988, -8.4631, -0.5224],\n",
      "         [-6.7565, -2.5214, -3.6790,  ..., -5.1184, -8.3889, -0.5143],\n",
      "         [-6.5447, -2.5575, -3.6595,  ..., -5.0701, -8.0698, -0.5219]],\n",
      "\n",
      "        [[-6.6652, -2.5016, -3.6348,  ..., -5.0385, -8.0125, -0.5573],\n",
      "         [-6.8530, -2.4951, -3.6564,  ..., -5.1162, -8.3995, -0.5264],\n",
      "         [-6.8810, -2.5067, -3.6538,  ..., -5.1087, -8.4959, -0.5238],\n",
      "         ...,\n",
      "         [-6.8078, -2.5115, -3.6682,  ..., -5.0987, -8.4639, -0.5224],\n",
      "         [-6.7576, -2.5206, -3.6790,  ..., -5.1186, -8.3902, -0.5142],\n",
      "         [-6.5462, -2.5567, -3.6598,  ..., -5.0706, -8.0715, -0.5217]],\n",
      "\n",
      "        [[-6.6655, -2.5014, -3.6345,  ..., -5.0383, -8.0128, -0.5573],\n",
      "         [-6.8534, -2.4948, -3.6562,  ..., -5.1160, -8.3999, -0.5264],\n",
      "         [-6.8813, -2.5064, -3.6536,  ..., -5.1084, -8.4963, -0.5238],\n",
      "         ...,\n",
      "         [-6.8081, -2.5110, -3.6683,  ..., -5.0987, -8.4643, -0.5224],\n",
      "         [-6.7580, -2.5201, -3.6792,  ..., -5.1186, -8.3908, -0.5142],\n",
      "         [-6.5467, -2.5562, -3.6599,  ..., -5.0708, -8.0722, -0.5217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.6664, -2.5005, -3.6333,  ..., -5.0386, -8.0141, -0.5575],\n",
      "         [-6.8546, -2.4939, -3.6551,  ..., -5.1162, -8.4019, -0.5264],\n",
      "         [-6.8823, -2.5056, -3.6526,  ..., -5.1084, -8.4982, -0.5239],\n",
      "         ...,\n",
      "         [-6.8085, -2.5106, -3.6684,  ..., -5.0991, -8.4663, -0.5224],\n",
      "         [-6.7584, -2.5198, -3.6795,  ..., -5.1194, -8.3928, -0.5141],\n",
      "         [-6.5470, -2.5559, -3.6604,  ..., -5.0720, -8.0742, -0.5215]],\n",
      "\n",
      "        [[-6.6665, -2.5005, -3.6332,  ..., -5.0385, -8.0144, -0.5575],\n",
      "         [-6.8549, -2.4939, -3.6550,  ..., -5.1161, -8.4023, -0.5264],\n",
      "         [-6.8825, -2.5056, -3.6526,  ..., -5.1083, -8.4987, -0.5239],\n",
      "         ...,\n",
      "         [-6.8084, -2.5105, -3.6685,  ..., -5.0990, -8.4666, -0.5224],\n",
      "         [-6.7583, -2.5196, -3.6796,  ..., -5.1193, -8.3930, -0.5141],\n",
      "         [-6.5468, -2.5557, -3.6604,  ..., -5.0718, -8.0742, -0.5215]],\n",
      "\n",
      "        [[-6.6664, -2.5004, -3.6327,  ..., -5.0378, -8.0143, -0.5576],\n",
      "         [-6.8552, -2.4938, -3.6548,  ..., -5.1156, -8.4028, -0.5264],\n",
      "         [-6.8830, -2.5055, -3.6525,  ..., -5.1079, -8.4996, -0.5238],\n",
      "         ...,\n",
      "         [-6.8092, -2.5101, -3.6689,  ..., -5.0991, -8.4680, -0.5223],\n",
      "         [-6.7590, -2.5191, -3.6799,  ..., -5.1193, -8.3942, -0.5141],\n",
      "         [-6.5470, -2.5552, -3.6606,  ..., -5.0715, -8.0749, -0.5216]]],\n",
      "       device='cuda:0')\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "[\"i can't imagine not being able to\", \"was left standing alone by the side of the butterfly's eggs a pretty nurse she has chosen indeed poor lady exclaimed she and a pretty business i have in hand why her senses must have left her\", 'became lawless in the extreme meanwhile the president had drafted the young men of america in their millions to die on foreign soil for foreign democracy he had issued a special appeal to women to give their work their treasure and their sons to this enterprise', 'the thought of having to live under a trader was so terrible he was moved to escape leaving his wife to whom he had only been married three months henry was twenty five years of age', \"so he didn't find the time long at all it was a beautiful fairy story marilla i forgot the end of it so i made up an end for it myself and matthew said he couldn't tell where the join came in matthew would think it all right anne if you took a notion to get up and have dinner in the middle of the night\", \"no one with any eyes at all could have helped seeing him because of that wonderful scarlet coat he saw too by the way redcoat was acting that he was in great trouble as farmer brown's boy drew near and redcoat saw that he was discovered\", 'entirely futile and negligible', 'the good natured princess at once left her home and her family and hurried to the ruined castle and took possession of the room with the golden bed', \"therefore let's concentrate on our chances of being crushed or asphyxiated as for asphyxiation captain i replied that isn't a cause for alarm because the air tanks are full true\", \"all this roaming over the plain at bobby's heels but i happened to take the right course when the trail was found there was the saddle to look for and this was located with some difficulty\", 'men make use of other goods while they are storing up a supply of wood or coal it may be looked upon as the income but they may burn it to help grow hothouse plants', 'young onions and the man who was weeding them paused from his labour long enough to sell me a handful near by was the smoke blackened ruin of the farmhouse fired by the russians when they retreated from the riverbed two men were removing the debris', \"with the service of the ship's men leaving unalaska the sun shone clear and cold upon the mountains where in places the sides looked black from the late fires started in the deep tundra by miscreants\", 'where he spent his time in knocking his head against the wall until the courtiers were afraid he would kill himself they accordingly placed stuffed mattresses over every wall and allowed all his subjects who desired', 'have you investigated the farm at all i looked up a real estate dealer living at millville and wrote him about the wegg farm he said if any one wanted the place very badly it might sell for three thousand dollars humph', 'and joined my sad tears to theirs all this time no distinct idea presented itself to my mind']\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CTCLoss(blank=28).to(device)\n",
    "with torch.no_grad():\n",
    "    for i, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        # loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        # test_loss += loss.item() / len(test_loader)\n",
    "        print(output)\n",
    "        decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "        \n",
    "        print(decoded_preds)\n",
    "        print(decoded_targets)\n",
    "        \n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}